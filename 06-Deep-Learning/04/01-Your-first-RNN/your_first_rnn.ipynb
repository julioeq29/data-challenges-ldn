{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Day 4 - Exercise 1\n",
    "\n",
    "You will here build your first Recurrent Neural Network (RNN). Not to consider to complex data, we will here just make the model compile and run on random data, to see the effect of the different options and parameters. So no need to interpret the results here.\n",
    "\n",
    "\n",
    "# The data\n",
    "\n",
    "We will create fake/random data here. \n",
    "\n",
    "❓ **Question** ❓ Create fake data where :\n",
    "- Each observation is of size 3: `[2.2, 3.8, -1.2]` for instance.\n",
    "- The first sequence `X_1` has 4 observations. \n",
    "- The first sequence `X_2` has 7 observations. \n",
    "- The third sequence `X_3` has 1 observation. \n",
    "- The last sequence `X_4` has 3 observations.\n",
    "- Each output `y_1` to`y_4` is a scalar value - let's say that it will be a regression task with one value to predict\n",
    "\n",
    "❗ **Remark** ❗ You can image that each observation corresponds to a job experience where the three features are (duration of the job, salary of the job, number of person under your responsability). And `X_1` thus corresponds to a sequence of 3 jobs, that someone has done. Same goes for `X_2` that is a sequence of 7 jobs, `X_3` and `X_4`. And the $y$ corresponds to the salary of the next job that you are trying to predict.\n",
    "\n",
    "❗ **Remark** ❗ Make sure that some of the data are floats, not integers.\n",
    "\n",
    "Hint: You can, for instance, use `numpy.random.normal`\n",
    "\n",
    "\n",
    "\n",
    "At the end, the data should be store in $X$ and $y$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "X = np.array([X_1, X_2, X_3, X_4])\n",
    "y = np.array([y_1, y_2, y_3, y_4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You remember that we pass a batch of data to the neural network. Thus, the tensor will has the following shape (batch_size, number_of_observations, size_of_observation).\n",
    "\n",
    "While size_of_observation is the same (=3) for all the sequences, the number_of_observations is different for each sequence. But it can't be like that in practice, for computational reason. So we will have (batch_size, max(number_of_observations), size_of_observation), so that each sequence has the same size.\n",
    "\n",
    "We will do that we the `pad_sequences` function of keras. It basically adds 0 to fill in the blank.\n",
    "\n",
    "❓ **Question** ❓ Use the `pad_sequences` function on X directly (without extra arguments here), store the result in `X_pad` and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ You probably see that the returned data are integers, instead of float. To change that, turn the `dtype` argument to `float32`. Moreover, add the `0` at the end of the sequence thanks to the `padding` argument. And finally, in the case where your fake data contains the `0` values, you cannot pad with `0`, so choose another value with the `value` keyword.\n",
    "\n",
    "❗ **Remark** ❗ Store the new result in `X_pad` and print it to be sure \n",
    "\n",
    "[See full documentation here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Print the `X_pad` shape. Check that the assert is verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "assert(X_pad.shape == (4, 7, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "Now, you will create your first Recurrent Neural Network.\n",
    "\n",
    "❓ **Question** ❓ Write a model that has: \n",
    "- a first Masking layer whose role is computational only: as you have padded the input data, you have to 'un-pad' them so that the Network does not use the padded values.\n",
    "- a second LSTM layer ; choose any `units` number but don't forget to choose the `tanh` activation function\n",
    "- a last Dense layer specific to your task\n",
    "\n",
    "❗ **Remark** ❗ If you have padded your input data with values different from 0, you should inform the Masking layer about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Compile your model. Remember to first use the `rmsprop` optimizer (instead of Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Run your model on your data. Do not use any validation set nor early stopping criterion as this are fake data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, build Neural Network whose RNN part is a `GRU`. Compile it and fit it then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well done!\n",
    "\n",
    "## You now know how to run RNN on sequence data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
