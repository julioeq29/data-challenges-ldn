{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Day 2 - Exercise 3\n",
    "\n",
    "In this exercise, we will try to generate some text. The underlying idead is to ginve a input sequence and to predict what the next word is going to be. To do that, we will first create a dataset for this task, and then run a RNN to do the prediction.\n",
    "\n",
    "# The data\n",
    "\n",
    "❓ Question ❓ First, let's load the data. Here, it is the IMDB reviews again, but we are only interested in the sentences, not the positiveness or negativeness of the review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Write a function that, given a sentence (list of words), returns\n",
    "- a list of words that corresponds to part of the sentence \n",
    "- the word that follow the previous sequence\n",
    "\n",
    "❗ **Remark** ❗ There is no reason your first list of words to start by the beginning of the input sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Check that the function is working on some sentences from the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Write a function, that, based on the previous function and the loaded sentences, generate a dataset X and y:\n",
    "- each sample of X is a split of a sentence\n",
    "- the corresponding y is the word that comes just after in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Split X and y in train and test data. Store it in `sentences_train`, `sentences_test`, `y_train` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ In a dictionary, store a unique token for each word. The key is the word while the value is the corresponding token. Then, in another dictionary, revert it to have the token as the key and the word as the dictionary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Based on the previous dictionary, tokenize the sentences and stores them in `X_train` and `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, pad your inputs and store them in `X_train_pad` and `X_test_pad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are currently words. We need to do multiple operations to use them. First, we need to tokenize them. Then, we need to convert them into categories (one-hot encoded, thanks to the `to_categorical`). However, this conversion should be done on the train set, and there is a possibility that some values are present in the test set but not in the train set.\n",
    "\n",
    "❓ **Question** ❓ For all these reasons, we need to tokenize `y_train` and `y_test` while converting words which are in `y_test` and not in `y_train` to another additional token which will correspond to an unseen word. You can have the same token for all these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, let's convert the tokenized outputs to categories! There should be as many categories as different words in `y_train`, plus one which corresponds to the prediction of an unseen word in the `y_train` but which will be useful once evaluated on the `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "❓ **Question** ❓ Write a RNN with all the appropriate layers, and compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Evaluate your model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Even though the model is not perfect, you can look at its prediction with a sentence of your choice. Don't forget to decoded the predicted token to know which word it corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Try to optimize your architecture to improve your performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Letter generation\n",
    "\n",
    "You have probably seen that the previous task is actually not easy to tackle. Current state-of-the-art RNN for NLP use particular and comple techniques to tackle such challenges.\n",
    "\n",
    "Now, in a more autonomous way, try to recreate the previous pipeline but to generate letters instead of entire word.\n",
    "\n",
    "Your input should be a string, for instance 'This is a good movie where the act'. And the output, the prediction, should be a string: it can be a letter, but it can be a space ' ', a number '1', '2', ... or a special character.\n",
    "\n",
    "The idea is quite similar except that you will have now tokens that corresponds to letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
